(Database)=
# Database

## ER Diagram

```{figure} ./database.png
[ER diagram](https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model) of the database (generated by `scripts/generate-database-diagram.sh` using [SchemaCrawler](https://www.schemacrawler.com/diagramming.html)); you might want to zoom in ðŸ˜‰
```


## SQL

AMARCORD is built on top of the concept of a [relational database](https://en.wikipedia.org/wiki/Relational_database) (an SQL database). Due to the use of Python's [SQLAlchemy](https://www.sqlalchemy.org/) library, the concrete type of SQL database shouldn't matter much. We're using both [SQLite](https://www.sqlite.org/index.html) and MySQL, with the same code base.

## Configuration

Per beamtime, there is a `UserConfiguration` table (see diagram above). A beamtime can have multiple user configuration states, but in practice, AMARCORD always retrieves the latest one to check the current state.

## Geometries

Geometries are represented by the `Geometry` table. A geometry currently is more or less hard-coded to be a CrystFEL geometry. However, there can be two types of geometries (signified by the `GeometryType` enum): one where the complete geometry file is stored inside the database (`CRYSTFEL_STRING`) and one where the contents are actually stored inside a file on the file system (`CRYSTFEL_FILE`). The type is currently very implicit: if you start your geometry with a slash `/`, then it's a file. Otherwise, it's a string.

## Attributi

While the database, being an SQL-based database, has a fixed schema, scientific experiments are quite different from one another. To account for that, we have a table for so-called "Attributi" (singular "Attributo"), which are additional columns for both runs and chemicals (see below) that can be created and filled by the experimenter, and not the programmer.

## Files

In order to avoid complexity with respect to permissions and file-system mounting, you can actually store arbitrary files in the database. All database engines support this, so it's not a "hack". The following metadata is stored per file:

- Unique numeric ID (the database primary key)
- Type: a mime-type determined heuristically using the `libmagic` library
- SHA256 hash of the original file
- File name: the original file name (the database doesn't know about file names anymore, but in case we want to offer a download endpoint)
- Size in bytes of the original file
- Compressed size in bytes (optional)
- Original path: if available, where the file was stored on the original file system
- Modified timestamp
- User-editable description of the file
- Contents

In order to keep the size of the content manageable, gzip compression can be applied to files. There is an "auto" mode in the API to not compress small files, otherwise you can enable/disable compression as needed. The SHA256 hash in the DB refers to the original contents of the file, not the compressed ones.

The API also has a "deduplicate" flag in order to optionally return an existing file (via sha256 comparison) instead of always creating a new one.

## Live-stream images

Per beamtime, we have one (optional) special file: the live-stream image. The file is, in principle, only special by its file name, which has to be `live-stream-image-$beamtimeid`. This image is then used in two places:

1. When creating an event via the API, you can specify to include the current live stream image. This copies the file in its current state into a new file and attaches it to the new event created.
2. When retrieving the run overview, the current live stream image is returned as well, so it can be displayed.

You might think: why only one live image? There's no specific reason! We have not gotten around to implement it yet.

To *populate* the live image, we have one daemon that periodically grabs images from an [MJPEG](https://en.wikipedia.org/wiki/Motion_JPEG) stream, so you might be able to use that as-is. The daemon replaces the file with the latest image. 

(Alembic)=
## Migrations with alembic

AMARCORD uses [alembic](https://alembic.sqlalchemy.org/en/latest/), which is a companion library to SQLAlchemy providing the concept of *migrations*. A migration is a Python script that you can apply to any database (that is supported by SQLAlchemy, of course) and *change* it in some way. For example, if you add another column to a table, you write a migration that issues an `ALTER TABLE` statement. This way, you have a versioning scheme in your database, similar to having your source code version-controlled via [git](https://git-scm.com/). And similar to git commits, a migration has a unique (but optional) predecessor.

## Different database URLs

The [SQLAlchemy documentation](https://docs.sqlalchemy.org/en/20/core/engines.html) has examples for the most popular SQL databases and which URLs to use. Some examples:

- `sqlite+aiosqlite:////file` for **sqlite**
- `mysql+pymysql://scott:tiger@localhost/foo` for **MySQL**
- `postgresql+asyncpg://scott:tiger@localhost/mydatabase` for **Postgres**

Note that since we use Python's [asyncio](https://docs.python.org/3/library/asyncio.html), we have to use drivers that use asyncio as well, such as `asyncpg`. It might be necessary to `pip install` drivers to make that happen. Open an issue or a merge request if you encounter this scenario.
